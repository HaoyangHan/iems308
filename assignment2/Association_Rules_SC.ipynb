{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules\n",
    "## Submitted By: Anubhav Gupta\n",
    "## Date: 02/06/2018\n",
    "\n",
    "\n",
    "## Data Transformations in SQL\n",
    "\n",
    "##### Identified the following features of the pos.tansact table in the database:\n",
    "* C1 == SKU\n",
    "* C2 == STORE\n",
    "* C3 == REGISTER\n",
    "* C4 == TRANNUM\n",
    "* C6 == SALEDATE\n",
    "* C7 == STYPE\n",
    "\n",
    "##### Ran the following 1-time queries to Extract, Transform and Load into the schema. Notice that a unique STORE, REGISTER, TRANNUM and SALEDATE combination gives us 1 basket. Also, we pick only the 'Purchase' transactions.\n",
    "\n",
    "```\n",
    "CREATE TABLE agq3445_schema.trnsact_baskets AS\n",
    "SELECT c1 AS sku, \n",
    "    NULLIF(c2, '')::int as store,\n",
    "    to_timestamp(c6, 'YYYY-MM-DD') as datetran,\n",
    "    c2||','||c3||','||c4||','||c6 as basketId \n",
    "        FROM pos.trnsact where c7='P';\n",
    "```\n",
    "\n",
    "##### Added the following indexes to make the queries run fast. We cluster the trnsact_baskets table by datetran field so that we can do fast range queries\n",
    "\n",
    "```\n",
    "CREATE INDEX idx_datetran\n",
    "    ON agq3445_schema.trnsact_baskets USING btree\n",
    "    (datetran ASC NULLS LAST)\n",
    "\n",
    "ALTER TABLE agq3445_schema.trnsact_baskets\n",
    "    CLUSTER ON idx_datetran;\n",
    "\n",
    "CREATE INDEX idx_sku\n",
    "    ON agq3445_schema.trnsact_baskets USING btree\n",
    "    (sku ASC NULLS LAST);\n",
    "    \n",
    "CREATE INDEX idx_store\n",
    "    ON agq3445_schema.trnsact_baskets USING btree\n",
    "    (store ASC NULLS LAST);\n",
    "```\n",
    "\n",
    "##### Once the heavy lifting is done, we proceed to perform exploratory analysis on the new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries and connecting to the database\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2 as pg\n",
    "from orangecontrib.associate.fpgrowth import *\n",
    "import properties\n",
    "\n",
    "#Add properties file of the following format:\n",
    "#host=\"<host_name>\"\n",
    "#dbname=\"<db_name>\"\n",
    "#user=\"<username>\"\n",
    "#password=\"<password>\"\n",
    "\n",
    "conn_string = \"host='%s' dbname='%s' user='%s' password='%s'\" % (properties.host, properties.dbname, properties.user, properties.password)\n",
    "print(\"Connecting to database\\n%s\" % (conn_string))\n",
    "conn = pg.connect(conn_string)\n",
    "\n",
    "def execute_query(query_str):\n",
    "    return pd.read_sql(query_str, con = conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding the range of dates for which transactions are available\n",
    "df = execute_query(\"select min(datetran), max(datetran) from agq3445_schema.trnsact_baskets\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For each date find and plot the number of transactions across all the stores\n",
    "df = execute_query(\"select datetran, count(*) from agq3445_schema.trnsact_baskets group by datetran\")\n",
    "\n",
    "plt.figure()\n",
    "dates = [pd.to_datetime(d) for d in df['datetran']]\n",
    "plt.scatter(dates, df['count'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.show()\n",
    "\n",
    "#There doesn't seem to be a decipherable pattern in the counts, so we can do sampling according to the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding total number of stores\n",
    "\n",
    "df = execute_query(\"select count(distinct(store)) as stores from pos.strinfo\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding number of stores with transaction data\n",
    "\n",
    "df = execute_query(\"select count(distinct(store)) from agq3445_schema.trnsact_baskets\")\n",
    "print(df)\n",
    "\n",
    "#This means we have transaction data for 332/453 stores available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding number of stores with respective transaction counts\n",
    "\n",
    "df = execute_query(\"select store, count(*) as num_transactions from agq3445_schema.trnsact_baskets group by store\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding number of skus defined for the dataset\n",
    "\n",
    "df = execute_query(\"select count(distinct(sku)) as num_skus from pos.skuinfo\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing data subsetting by selecting transactions across all the stores for August 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = execute_query(\"SELECT basketid, sku FROM agq3445_schema.trnsact_baskets where datetran > '2005-08-01 00:00:00-05'\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Doing some exploration on the subset\n",
    "\n",
    "num_baskets = len(df.basketid.unique())\n",
    "unique_skus = len(df.sku.unique())\n",
    "num_transactions = len(df.index)\n",
    "\n",
    "print(\"Total number of transactions: \", num_transactions)\n",
    "print(\"Total number of baskets: \", num_baskets)\n",
    "print(\"Average basket size in the data subset: \" + str(int(num_transactions/num_baskets)))\n",
    "print(\"Total number of unique skus in the transaction data subset: \", unique_skus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reshaping each basket into list of SKUs\n",
    "baskets_set = list(df['sku'].groupby(df['basketid']))\n",
    "for i in range(len(baskets_set)):\n",
    "    indexed_transaction = list(baskets_set[i][1:])[0]\n",
    "    baskets_set[i] = [trans for trans in indexed_transaction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from orangecontrib.associate.fpgrowth import *\n",
    "\n",
    "itemsets = dict(frequent_itemsets(baskets_set, 600))\n",
    "rules = list(association_rules(itemsets, 0.2))\n",
    "rules_stats = rules_stats(rules, itemsets, num_baskets)\n",
    "final_rules_stats = list(rules_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading sku information from the table\n",
    "skus = pd.read_sql(\"SELECT * from pos.skuinfo\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_sku_details(set_sku):\n",
    "    str_sku = []\n",
    "    str_dept = []\n",
    "    str_brand = []\n",
    "    for sku in set_sku:\n",
    "        str_sku.append(re.sub(\"\\D\", \"\",sku))\n",
    "        if not skus.loc[skus['sku'] == int(sku)].empty: \n",
    "            str_dept.append(str((skus.loc[skus['sku'] == int(sku)])['dept'].values[0]))\n",
    "            str_brand.append(str((skus.loc[skus['sku'] == int(sku)])['brand'].values[0]).strip())\n",
    "    return str_sku, str_dept, str_brand \n",
    "\n",
    "final_rules_stats_new = []\n",
    "for i in range(len(final_rules_stats)): \n",
    "    str_skus_lhs, str_dept_lhs, str_brand_lhs = get_sku_details(final_rules_stats[i][0])\n",
    "    str_skus_rhs, str_dept_rhs, str_brand_rhs = get_sku_details(final_rules_stats[i][1])\n",
    "    final_rules_stats_new.append([str_skus_lhs, str_dept_lhs, str_brand_lhs, str_skus_rhs, str_dept_rhs, str_brand_rhs,\n",
    "                            final_rules_stats[i][2], final_rules_stats[i][3], final_rules_stats[i][6]])\n",
    "\n",
    "\n",
    "final_output = pd.DataFrame(final_rules_stats_new, columns = [\"Antecedent_SKUs\",\"Antecedent_Dept\",\"Antecedent_Brand\", \"Consequent_SKUs\",\"Consequent_Dept\",\"Consequent_Brand\", \"Support\", \"Confidence\",\"Lift\"])\n",
    "final_output = final_output.sort_values(by='Lift', ascending=False)     \n",
    "final_output.to_csv(\"output.csv\", header=\"true\", index=False)\n",
    "final_output\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
